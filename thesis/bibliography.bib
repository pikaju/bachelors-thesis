@article{a3c,
  author        = {{Mnih}, Volodymyr and {Puigdom{\`e}nech Badia}, Adri{\`a} and
         {Mirza}, Mehdi and {Graves}, Alex and {Lillicrap}, Timothy P. and
         {Harley}, Tim and {Silver}, David and {Kavukcuoglu}, Koray},
  title         = {{Asynchronous Methods for Deep Reinforcement Learning}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning},
  year          = 2016,
  month         = feb,
  eid           = {arXiv:1602.01783},
  pages         = {arXiv:1602.01783},
  archiveprefix = {arXiv},
  eprint        = {1602.01783},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2016arXiv160201783M},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@inbook{back-propagation,
  author    = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  title     = {Learning Representations by Back-Propagating Errors},
  year      = {1988},
  isbn      = {0262010976},
  publisher = {MIT Press},
  address   = {Cambridge, MA, USA},
  booktitle = {Neurocomputing: Foundations of Research},
  pages     = {696â€“699},
  numpages  = {4}
}

@book{bible,
  added-at  = {2019-07-13T10:11:53.000+0200},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  biburl    = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition   = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords  = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title     = {Reinforcement Learning: An Introduction},
  url       = {http://incompleteideas.net/book/the-book-2nd.html},
  year      = {2018 }
}

@article{curious,
  author        = {{Aubret}, Arthur and {Matignon}, Laetitia and {Hassas}, Salima},
  title         = {{A survey on intrinsic motivation in reinforcement learning}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
  year          = 2019,
  month         = aug,
  eid           = {arXiv:1908.06976},
  pages         = {arXiv:1908.06976},
  archiveprefix = {arXiv},
  eprint        = {1908.06976},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv190806976A},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{first-neuron,
  added-at             = {2008-02-26T11:58:58.000+0100},
  author               = {Mcculloch, Warren and Pitts, Walter},
  biburl               = {https://www.bibsonomy.org/bibtex/26fbacb0ae04bc17d296d9265dfc90dff/schaul},
  citeulike-article-id = {2380493},
  description          = {idsia},
  interhash            = {3e8e0d06f376f3eb95af89d5a2f15957},
  intrahash            = {6fbacb0ae04bc17d296d9265dfc90dff},
  journal              = {Bulletin of Mathematical Biophysics},
  keywords             = {evolutionary},
  pages                = {127--147},
  priority             = {2},
  timestamp            = {2008-02-26T12:00:58.000+0100},
  title                = {A Logical Calculus of Ideas Immanent in Nervous Activity},
  volume               = 5,
  year                 = 1943
}

@article{first-perceptron,
  author  = {F. Rosenblatt},
  title   = {The Perceptron: A Probabilistic Model for Information Storage and Organization in The Brain},
  journal = {Psychological Review},
  year    = {1958},
  pages   = {65--386}
}

@article{gym,
  author        = {{Brockman}, Greg and {Cheung}, Vicki and {Pettersson}, Ludwig and
         {Schneider}, Jonas and {Schulman}, John and {Tang}, Jie and
         {Zaremba}, Wojciech},
  title         = {{OpenAI Gym}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
  year          = 2016,
  month         = jun,
  eid           = {arXiv:1606.01540},
  pages         = {arXiv:1606.01540},
  archiveprefix = {arXiv},
  eprint        = {1606.01540},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2016arXiv160601540B},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{muzero,
  author        = {{Schrittwieser}, Julian and {Antonoglou}, Ioannis and {Hubert}, Thomas and
         {Simonyan}, Karen and {Sifre}, Laurent and {Schmitt}, Simon and
         {Guez}, Arthur and {Lockhart}, Edward and {Hassabis}, Demis and
         {Graepel}, Thore and {Lillicrap}, Timothy and {Silver}, David},
  title         = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  year          = 2019,
  month         = nov,
  eid           = {arXiv:1911.08265},
  pages         = {arXiv:1911.08265},
  archiveprefix = {arXiv},
  eprint        = {1911.08265},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv191108265S},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{q-learning,
  abstract  = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  added-at  = {2020-01-01T20:16:30.000+0100},
  author    = {Watkins, Christopher J. C. H. and Dayan, Peter},
  biburl    = {https://www.bibsonomy.org/bibtex/2416ac9f845c6ccea5a7eacee4dedead8/lanteunis},
  day       = 01,
  doi       = {10.1007/BF00992698},
  interhash = {a4436f9e14335d677f156049cb798253},
  intrahash = {416ac9f845c6ccea5a7eacee4dedead8},
  issn      = {1573-0565},
  journal   = {Machine Learning},
  keywords  = {DRLAlgoComparison q-learning reinforcement_learning},
  month     = may,
  number    = 3,
  pages     = {279--292},
  timestamp = {2020-01-01T20:16:30.000+0100},
  title     = {Q-learning},
  url       = {https://doi.org/10.1007/BF00992698},
  volume    = 8,
  year      = 1992
}

@book{reinforce,
  added-at  = {2019-07-13T10:11:53.000+0200},
  author    = {Williams, Ronald J.},
  publisher = {Kluwer Academic Publishers},
  title     = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  url       = {https://link.springer.com/content/pdf/10.1007/BF00992696.pdf},
  year      = {1992}
}

@article{td-learning,
  author  = {Sutton, Richard},
  year    = {1988},
  month   = {08},
  pages   = {9-44},
  title   = {Learning to Predict by the Method of Temporal Differences},
  volume  = {3},
  journal = {Machine Learning},
  doi     = {10.1007/BF00115009}
}

@article{tensor-cores,
  author        = {Stefano Markidis and
               Steven Wei Der Chien and
               Erwin Laure and
               Ivy Bo Peng and
               Jeffrey S. Vetter},
  title         = {{NVIDIA} Tensor Core Programmability, Performance {\&} Precision},
  journal       = {CoRR},
  volume        = {abs/1803.04014},
  year          = {2018},
  url           = {http://arxiv.org/abs/1803.04014},
  archiveprefix = {arXiv},
  eprint        = {1803.04014},
  timestamp     = {Mon, 13 Aug 2018 16:46:46 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1803-04014.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{thorndike,
  author    = {Thorndike, Edward},
  title     = {Some experiments on animal intelligence},
  volume    = {7},
  number    = {181},
  pages     = {818--824},
  year      = {1898},
  doi       = {10.1126/science.7.181.818},
  publisher = {American Association for the Advancement of Science},
  issn      = {0036-8075},
  url       = {https://science.sciencemag.org/content/7/181/818},
  eprint    = {https://science.sciencemag.org/content/7/181/818.full.pdf},
  journal   = {Science}
}

