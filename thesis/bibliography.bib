@article{acer,
  author        = {Ziyu Wang and
               Victor Bapst and
               Nicolas Heess and
               Volodymyr Mnih and
               R{\'{e}}mi Munos and
               Koray Kavukcuoglu and
               Nando de Freitas},
  title         = {{Sample Efficient Actor-Critic with Experience Replay}},
  journal       = {CoRR},
  volume        = {abs/1611.01224},
  year          = {2016},
  url           = {http://arxiv.org/abs/1611.01224},
  archiveprefix = {arXiv},
  eprint        = {1611.01224},
  timestamp     = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/WangBHMMKF16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{alphastar,
  title   = {{Grandmaster level in StarCraft II using multi-agent reinforcement learning}},
  volume  = {575},
  issn    = {0028-0836},
  doi     = {10.1038/s41586-019-1724-z},
  number  = {7782},
  journal = {Nature},
  author  = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and et al.},
  year    = {2019},
  pages   = {350–354}
}

@article{alphazero,
  author        = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title         = {{Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm}},
  journal       = {CoRR},
  volume        = {abs/1712.01815},
  year          = {2017},
  url           = {http://arxiv.org/abs/1712.01815},
  archiveprefix = {arXiv},
  eprint        = {1712.01815},
  timestamp     = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{a3c,
  author        = {{Mnih}, Volodymyr and {Puigdom{\`e}nech Badia}, Adri{\`a} and
         {Mirza}, Mehdi and {Graves}, Alex and {Lillicrap}, Timothy P. and
         {Harley}, Tim and {Silver}, David and {Kavukcuoglu}, Koray},
  title         = {{Asynchronous Methods for Deep Reinforcement Learning}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning},
  year          = 2016,
  month         = feb,
  eid           = {arXiv:1602.01783},
  pages         = {arXiv:1602.01783},
  archiveprefix = {arXiv},
  eprint        = {1602.01783},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2016arXiv160201783M},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@inbook{back-propagation,
  author    = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  title     = {{Learning Representations by Back-Propagating Errors}},
  year      = {1988},
  isbn      = {0262010976},
  publisher = {MIT Press},
  address   = {Cambridge, MA, USA},
  booktitle = {Neurocomputing: Foundations of Research},
  pages     = {696–699},
  numpages  = {4}
}

@book{bible,
  added-at  = {2019-07-13T10:11:53.000+0200},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  biburl    = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition   = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords  = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title     = {{Reinforcement Learning: An Introduction}},
  url       = {http://incompleteideas.net/book/the-book-2nd.html},
  year      = {2018 }
}

@article{bio-neuron,
  author        = {B. Mehlig},
  title         = {{Artificial Neural Networks}},
  journal       = {CoRR},
  volume        = {abs/1901.05639},
  year          = {2019},
  url           = {http://arxiv.org/abs/1901.05639},
  archiveprefix = {arXiv},
  eprint        = {1901.05639},
  timestamp     = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1901-05639.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@misc{continuous-muzero,
  title         = {{Continuous Control for Searching and Planning with a Learned Model}},
  author        = {Xuxi Yang and Werner Duvaud and Peng Wei},
  year          = {2020},
  eprint        = {2006.07430},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@article{curious,
  author        = {{Aubret}, Arthur and {Matignon}, Laetitia and {Hassas}, Salima},
  title         = {{A survey on intrinsic motivation in reinforcement learning}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
  year          = 2019,
  month         = aug,
  eid           = {arXiv:1908.06976},
  pages         = {arXiv:1908.06976},
  archiveprefix = {arXiv},
  eprint        = {1908.06976},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv190806976A},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{double-dqn,
  author        = {Hado van Hasselt and
               Arthur Guez and
               David Silver},
  title         = {{Deep Reinforcement Learning with Double Q-learning}},
  journal       = {CoRR},
  volume        = {abs/1509.06461},
  year          = {2015},
  url           = {http://arxiv.org/abs/1509.06461},
  archiveprefix = {arXiv},
  eprint        = {1509.06461},
  timestamp     = {Mon, 13 Aug 2018 16:47:32 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/HasseltGS15.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{dqn,
  author        = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title         = {{Playing Atari with Deep Reinforcement Learning}},
  journal       = {CoRR},
  volume        = {abs/1312.5602},
  year          = {2013},
  url           = {http://arxiv.org/abs/1312.5602},
  archiveprefix = {arXiv},
  eprint        = {1312.5602},
  timestamp     = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{dueling-dqn,
  author        = {Ziyu Wang and
               Nando de Freitas and
               Marc Lanctot},
  title         = {{Dueling Network Architectures for Deep Reinforcement Learning}},
  journal       = {CoRR},
  volume        = {abs/1511.06581},
  year          = {2015},
  url           = {http://arxiv.org/abs/1511.06581},
  archiveprefix = {arXiv},
  eprint        = {1511.06581},
  timestamp     = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/WangFL15.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{first-neuron,
  added-at             = {2008-02-26T11:58:58.000+0100},
  author               = {Mcculloch, Warren and Pitts, Walter},
  biburl               = {https://www.bibsonomy.org/bibtex/26fbacb0ae04bc17d296d9265dfc90dff/schaul},
  citeulike-article-id = {2380493},
  description          = {idsia},
  interhash            = {3e8e0d06f376f3eb95af89d5a2f15957},
  intrahash            = {6fbacb0ae04bc17d296d9265dfc90dff},
  journal              = {Bulletin of Mathematical Biophysics},
  keywords             = {evolutionary},
  pages                = {127--147},
  priority             = {2},
  timestamp            = {2008-02-26T12:00:58.000+0100},
  title                = {{A Logical Calculus of Ideas Immanent in Nervous Activity}},
  volume               = 5,
  year                 = 1943
}

@article{first-perceptron,
  author  = {F. Rosenblatt},
  title   = {The Perceptron: A Probabilistic Model for Information Storage and Organization in The Brain},
  journal = {Psychological Review},
  year    = {1958},
  pages   = {65--386}
}

@article{gym,
  author        = {{Brockman}, Greg and {Cheung}, Vicki and {Pettersson}, Ludwig and
         {Schneider}, Jonas and {Schulman}, John and {Tang}, Jie and
         {Zaremba}, Wojciech},
  title         = {{OpenAI Gym}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
  year          = 2016,
  month         = jun,
  eid           = {arXiv:1606.01540},
  pages         = {arXiv:1606.01540},
  archiveprefix = {arXiv},
  eprint        = {1606.01540},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2016arXiv160601540B},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{joshua,
  author   = {Joshua Schimmelpfennig},
  title    = {Adaptive Goal-Directed Behavior using Planning with
Reinforcement Rewards},
  year     = {2019},
  language = {eng}
}

@inproceedings{l2-regularization,
  author    = {Ng, Andrew Y.},
  title     = {{Feature Selection, L1 vs. L2 Regularization, and Rotational Invariance}},
  year      = {2004},
  isbn      = {1581138385},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1015330.1015435},
  doi       = {10.1145/1015330.1015435},
  abstract  = {We consider supervised learning in the presence of very many irrelevant features, and study two different regularization methods for preventing overfitting. Focusing on logistic regression, we show that using L1 regularization of the parameters, the sample complexity (i.e., the number of training examples required to learn "well,") grows only logarithmically in the number of irrelevant features. This logarithmic rate matches the best known bounds for feature selection, and indicates that L1 regularized logistic regression can be effective even if there are exponentially many irrelevant features as there are training examples. We also give a lower-bound showing that any rotationally invariant algorithm---including logistic regression with L2 regularization, SVMs, and neural networks trained by backpropagation---has a worst case sample complexity that grows at least linearly in the number of irrelevant features.},
  booktitle = {Proceedings of the Twenty-First International Conference on Machine Learning},
  pages     = {78},
  numpages  = {8},
  location  = {Banff, Alberta, Canada},
  series    = {ICML '04}
}

@inproceedings{mcts,
  author    = {Rémi Coulom},
  title     = {{Efficient selectivity and backup operators in Monte-Carlo tree search}},
  booktitle = {In: Proceedings Computers and Games 2006},
  year      = {2006},
  publisher = {Springer-Verlag}
}

@incollection{model,
  title     = {{Planning with an Adaptive World Model}},
  author    = {Sebastian Thrun and Knut M\"{o}ller and Alexander Linden},
  booktitle = {Advances in Neural Information Processing Systems 3},
  editor    = {R. P. Lippmann and J. E. Moody and D. S. Touretzky},
  pages     = {450--456},
  year      = {1991},
  publisher = {Morgan-Kaufmann},
  url       = {http://papers.nips.cc/paper/365-planning-with-an-adaptive-world-model.pdf}
}

@article{muzero,
  author        = {{Schrittwieser}, Julian and {Antonoglou}, Ioannis and {Hubert}, Thomas and
         {Simonyan}, Karen and {Sifre}, Laurent and {Schmitt}, Simon and
         {Guez}, Arthur and {Lockhart}, Edward and {Hassabis}, Demis and
         {Graepel}, Thore and {Lillicrap}, Timothy and {Silver}, David},
  title         = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  year          = 2019,
  month         = nov,
  eid           = {arXiv:1911.08265},
  pages         = {arXiv:1911.08265},
  archiveprefix = {arXiv},
  eprint        = {1911.08265},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv191108265S},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{muzero-general,
  author       = {Werner Duvaud, Aurèle Hainaut},
  title        = {{MuZero General: Open Reimplementation of MuZero}},
  year         = {2019},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/werner-duvaud/muzero-general}}
}

@misc{openai-five,
  author       = {OpenAI},
  title        = {{OpenAI Five}},
  howpublished = {\url{https://blog.openai.com/openai-five/}},
  year         = 2018
}

@article{per,
  title   = {{Prioritized Experience Replay}},
  author  = {T. Schaul and John Quan and Ioannis Antonoglou and D. Silver},
  journal = {CoRR},
  year    = {2016},
  volume  = {abs/1511.05952}
}

@article{pytorch,
  author        = {{Paszke}, Adam and {Gross}, Sam and {Massa}, Francisco and
         {Lerer}, Adam and {Bradbury}, James and {Chanan}, Gregory and
         {Killeen}, Trevor and {Lin}, Zeming and {Gimelshein}, Natalia and
         {Antiga}, Luca and {Desmaison}, Alban and {K{\"o}pf}, Andreas and
         {Yang}, Edward and {DeVito}, Zach and {Raison}, Martin and
         {Tejani}, Alykhan and {Chilamkurthy}, Sasank and {Steiner}, Benoit and
         {Fang}, Lu and {Bai}, Junjie and {Chintala}, Soumith},
  title         = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
  journal       = {arXiv e-prints},
  keywords      = {Computer Science - Machine Learning, Computer Science - Mathematical Software, Statistics - Machine Learning},
  year          = 2019,
  month         = dec,
  eid           = {arXiv:1912.01703},
  pages         = {arXiv:1912.01703},
  archiveprefix = {arXiv},
  eprint        = {1912.01703},
  primaryclass  = {cs.LG},
  adsurl        = {https://ui.adsabs.harvard.edu/abs/2019arXiv191201703P},
  adsnote       = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{q-learning,
  abstract  = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  added-at  = {2020-01-01T20:16:30.000+0100},
  author    = {Watkins, Christopher J. C. H. and Dayan, Peter},
  biburl    = {https://www.bibsonomy.org/bibtex/2416ac9f845c6ccea5a7eacee4dedead8/lanteunis},
  day       = 01,
  doi       = {10.1007/BF00992698},
  interhash = {a4436f9e14335d677f156049cb798253},
  intrahash = {416ac9f845c6ccea5a7eacee4dedead8},
  issn      = {1573-0565},
  journal   = {Machine Learning},
  keywords  = {DRLAlgoComparison q-learning reinforcement_learning},
  month     = may,
  number    = 3,
  pages     = {279--292},
  timestamp = {2020-01-01T20:16:30.000+0100},
  title     = {{Q-learning}},
  url       = {https://doi.org/10.1007/BF00992698},
  volume    = 8,
  year      = 1992
}

@article{rainbow,
  author        = {Matteo Hessel and
               Joseph Modayil and
               Hado van Hasselt and
               Tom Schaul and
               Georg Ostrovski and
               Will Dabney and
               Daniel Horgan and
               Bilal Piot and
               Mohammad Gheshlaghi Azar and
               David Silver},
  title         = {{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
  journal       = {CoRR},
  volume        = {abs/1710.02298},
  year          = {2017},
  url           = {http://arxiv.org/abs/1710.02298},
  archiveprefix = {arXiv},
  eprint        = {1710.02298},
  timestamp     = {Mon, 13 Aug 2018 16:48:05 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1710-02298.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@book{reinforce,
  added-at  = {2019-07-13T10:11:53.000+0200},
  author    = {Williams, Ronald J.},
  publisher = {Kluwer Academic Publishers},
  title     = {{Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning}},
  url       = {https://link.springer.com/content/pdf/10.1007/BF00992696.pdf},
  year      = {1992}
}

@article{rubiks-cube,
  title   = {{Solving Rubik's Cube with a Robot Hand}},
  author  = {OpenAI and I. Akkaya and Marcin Andrychowicz and Maciek Chociej and Mateusz Litwin and Bob McGrew and Arthur Petron and Alex Paino and Matthias Plappert and Glenn Powell and Raphael Ribas and J. Schneider and N. Tezak and Jadwiga Tworek and P. Welinder and Lilian Weng and Q. Yuan and W. Zaremba and Lei Zhang},
  journal = {ArXiv},
  year    = {2019},
  volume  = {abs/1910.07113}
}

@article{sc2ai,
  author        = {Oriol Vinyals and
               Timo Ewalds and
               Sergey Bartunov and
               Petko Georgiev and
               Alexander Sasha Vezhnevets and
               Michelle Yeo and
               Alireza Makhzani and
               Heinrich K{\"{u}}ttler and
               John P. Agapiou and
               Julian Schrittwieser and
               John Quan and
               Stephen Gaffney and
               Stig Petersen and
               Karen Simonyan and
               Tom Schaul and
               Hado van Hasselt and
               David Silver and
               Timothy P. Lillicrap and
               Kevin Calderone and
               Paul Keet and
               Anthony Brunasso and
               David Lawrence and
               Anders Ekermo and
               Jacob Repp and
               Rodney Tsing},
  title         = {StarCraft {II:} {A} New Challenge for Reinforcement Learning},
  journal       = {CoRR},
  volume        = {abs/1708.04782},
  year          = {2017},
  url           = {http://arxiv.org/abs/1708.04782},
  archiveprefix = {arXiv},
  eprint        = {1708.04782},
  timestamp     = {Tue, 28 Jul 2020 10:30:05 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1708-04782.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@misc{sokoban,
  author       = {Schrader, Max-Philipp B.},
  title        = {{gym-sokoban}},
  year         = {2018},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/mpSchrader/gym-sokoban}},
  commit       = {#CommitId}
}

@article{td-learning,
  author  = {Sutton, Richard},
  year    = {1988},
  month   = {08},
  pages   = {9-44},
  title   = {{Learning to Predict by the Method of Temporal Differences}},
  volume  = {3},
  journal = {Machine Learning},
  doi     = {10.1007/BF00115009}
}

@misc{tensorflow,
  title  = { {TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems}},
  url    = {https://www.tensorflow.org/},
  note   = {Software available from tensorflow.org},
  author = {
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year   = {2015}
}

@article{tensor-cores,
  author        = {Stefano Markidis and
               Steven Wei Der Chien and
               Erwin Laure and
               Ivy Bo Peng and
               Jeffrey S. Vetter},
  title         = {{NVIDIA Tensor Core Programmability, Performance \& Precision}},
  journal       = {CoRR},
  volume        = {abs/1803.04014},
  year          = {2018},
  url           = {http://arxiv.org/abs/1803.04014},
  archiveprefix = {arXiv},
  eprint        = {1803.04014},
  timestamp     = {Mon, 13 Aug 2018 16:46:46 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1803-04014.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{thorndike,
  author    = {Thorndike, Edward},
  title     = {{Some experiments on animal intelligence}},
  volume    = {7},
  number    = {181},
  pages     = {818--824},
  year      = {1898},
  doi       = {10.1126/science.7.181.818},
  publisher = {American Association for the Advancement of Science},
  issn      = {0036-8075},
  url       = {https://science.sciencemag.org/content/7/181/818},
  eprint    = {https://science.sciencemag.org/content/7/181/818.full.pdf},
  journal   = {Science}
}
