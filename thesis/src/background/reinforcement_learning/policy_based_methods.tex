\subsubsection{Policy-Based Methods}
We now explain one possible approach to optimize an agent's behavior by directly manipulating its parameterized policy $\pi_\theta$ with regards to the expected returns $\mathbb{E}\left[G_t\right]$. Typically, this is done using gradient descent. The REINFORCE algorithm \cite{reinforce} defines an estimate for $\nabla_\theta \mathbb{E}\left[G_t \given S_t \right]$ as $\nabla_\theta \log \pi_\theta\left(A_t \given S_t\right) G_t$. Intuitively, this may be thought of as increasing or decreasing the probability of actions on a given trajectory based on the return.